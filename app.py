import streamlit as st
from playwright.sync_api import sync_playwright
import time
import subprocess
import zipfile
import io
import re
from datetime import datetime

# --- åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro+)", layout="centered")
st.title("ğŸ›¡ï¸ ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro+)")
st.markdown("æˆ°ç•¥è¨˜éŒ„å°ˆç”¨å·¥å…·ï¼šé‡å° Facebook å»£å‘Šæª”æ¡ˆåº« (Ads Library) ç­‰ã€Œç„¡é™æ²å‹•ã€èˆ‡ã€Œ...å±•é–‹ã€ç¶²ç«™é€²è¡Œæ·±åº¦å„ªåŒ–ã€‚")

# --- æ ¸å¿ƒï¼šç’°å¢ƒæª¢æŸ¥ ---
def ensure_browsers_installed():
    try:
        # å˜—è©¦å•Ÿå‹•ç€è¦½å™¨çœ‹æ˜¯å¦æˆåŠŸ
        with sync_playwright() as p:
            p.chromium.launch(headless=True)
    except Exception:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“ (ä¸‹è¼‰ç€è¦½å™¨ binary)..."):
            # é‡å° Streamlit Cloud æˆ–ç„¡é ­ç’°å¢ƒçš„è‡ªå‹•å®‰è£
            subprocess.run(["playwright", "install", "chromium"])
            st.success("æ ¸å¿ƒå°±ç·’ï¼")

if 'browser_checked' not in st.session_state:
    ensure_browsers_installed()
    st.session_state['browser_checked'] = True

# --- é€šç”¨å·¥å…·å‡½å¼ ---
def get_safe_filename(url, index=None):
    clean_url = re.sub(r'^https?://', '', url)
    safe_name = re.sub(r'[^a-zA-Z0-9]', '_', clean_url)
    if index is not None:
        return f"{index+1:02d}_{safe_name[:50]}.pdf"
    return f"{safe_name[:50]}.pdf"

# --- [é—œéµä¿®æ­£] æ·±åº¦äº’å‹•æ»¾å‹•é‚è¼¯ ---
def smart_scroll_and_expand(page):
    """
    é‡å° Infinite Scroll ç¶²ç«™çš„æ™ºæ…§æ»¾å‹•èˆ‡é»æ“Šå±•é–‹
    ä¿®æ­£ç‰ˆæœ¬ï¼šä½¿ç”¨ Playwright å…§å»ºçš„ text selector å’Œ force: True æé«˜å¯é æ€§ã€‚
    """
    
    # é»æ“Šç›®æ¨™ï¼šåŒ…å«é€™äº›æ–‡å­—æˆ–ç¬¦è™Ÿçš„å…ƒç´ 
    # Meta å»£å‘Šåº«å¸¸ç”¨çš„ç¸®ç•¥ç¬¦è™Ÿæ˜¯ '...' (åŠå½¢) æˆ– 'â€¦' (å…¨å½¢åˆªç¯€è™Ÿ)
    # æˆ‘å€‘å°‡ä½¿ç”¨ Playwright çš„ locator ä¾†å°‹æ‰¾åŒ…å«é€™äº›æ–‡å­—çš„å…ƒç´ ã€‚
    keywords = ['æŸ¥çœ‹æ›´å¤š', 'é¡¯ç¤ºæ›´å¤š', 'See more', 'Read more', 'å±•é–‹', 'æ›´å¤š', '...', 'â€¦', 'See details', 'About this ad']

    def click_all_expanders(page, keywords):
        clicked_count = 0
        for keyword in keywords:
            # ä½¿ç”¨ Playwright å…§å»ºçš„ text selector å°‹æ‰¾åŒ…å«é—œéµå­—çš„å…ƒç´ 
            # ä¸¦ä¸”å‡è¨­é€™äº›å…ƒç´ æ˜¯æŒ‰éˆ•æˆ–å¯é»æ“Šçš„ div/span
            
            # ä½¿ç”¨ contains selectorï¼Œä¸¦å°çŸ­æ–‡å­—/ç¬¦è™Ÿä½¿ç”¨ç²¾ç¢ºéæ¿¾
            locator = page.locator(f'text={keyword}')
            
            try:
                # éæ­·æ‰€æœ‰åŒ¹é…çš„å…ƒç´ 
                elements = locator.all()
                for el in elements:
                    text = el.inner_text().strip()
                    # é¿å…é»æ“Šå…§æ–‡ä¸­çš„é•·æ®µè½ï¼ˆå¦‚æ–‡ç« å…§æ–‡æ°å¥½æœ‰ ...ï¼‰
                    if len(text) < 30 or text in ('...', 'â€¦', 'æŸ¥çœ‹æ›´å¤š', 'See more'):
                        try:
                            # å˜—è©¦é»æ“Šï¼Œä½¿ç”¨ force: True æ‡‰å°éƒ¨åˆ†è¢«é®æ“‹çš„æƒ…æ³
                            el.click(timeout=1000, force=True)
                            clicked_count += 1
                        except:
                            pass # å¿½ç•¥é»æ“Šå¤±æ•— (å¯èƒ½æ˜¯å…ƒç´ å·²æ¶ˆå¤±æˆ–ç¢ºå¯¦ç„¡æ³•é»æ“Š)
            except:
                pass
        return clicked_count

    st.info("æ­£åœ¨åŸ·è¡Œåˆå§‹é»æ“Šå±•é–‹...")
    click_all_expanders(page, keywords)
    time.sleep(1) # è®“åˆå§‹å±•é–‹å®Œæˆ

    # æ™ºæ…§ç„¡é™æ²å‹•èˆ‡é‡è¤‡å±•é–‹
    previous_height = page.evaluate("document.body.scrollHeight")
    max_scrolls = 20
    
    for i in range(max_scrolls):
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        
        # FB è¼‰å…¥æ–°å…§å®¹éœ€è¦æ™‚é–“
        time.sleep(2.5) 
        
        st.info(f"æ»¾å‹•ä¸¦å†æ¬¡å˜—è©¦å±•é–‹ (ç¬¬ {i+1} æ¬¡)...")
        # åœ¨æ–°è¼‰å…¥çš„å…§å®¹ä¸Šå†æ¬¡åŸ·è¡Œé»æ“Šå±•é–‹
        click_all_expanders(page, keywords)
        time.sleep(1) # è®“æ–°å±•é–‹çš„å…§å®¹ç©©å®š

        new_height = page.evaluate("document.body.scrollHeight")
        
        if new_height == previous_height:
            # å¦‚æœé«˜åº¦æ²’è®Šï¼Œå†å¤šç­‰ä¸€ä¸‹ç¢ºèªæ˜¯å¦åˆ°åº•
            time.sleep(2)
            new_height = page.evaluate("document.body.scrollHeight")
            if new_height == previous_height:
                break # çœŸçš„åˆ°åº•äº†
        previous_height = new_height

    # ä»»å‹™çµæŸï¼Œæ»¾å›é ‚éƒ¨ä»¥ä¾¿æˆªåœ–æ™‚ç‰ˆé¢æ­£å¸¸
    page.evaluate("window.scrollTo(0, 0)")
    time.sleep(1)

# --- æ¨¡å¼ä¸€ï¼šå–®ä¸€ç¶²å€ ---
def generate_single_pdf(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        # åŠ å¤§ Viewport
        context = browser.new_context(
            viewport={"width": 1280, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        page = context.new_page()
        try:
            st.info(f"æ­£åœ¨é€£æ¥ï¼š{url}")
            page.goto(url, wait_until="domcontentloaded", timeout=60000)
            page.emulate_media(media="screen")
            
            st.info("æ­£åœ¨åŸ·è¡Œæ·±åº¦æŒ–æ˜ (æ»¾å‹•åŠ è¼‰ + é»æ“Š '...' å±•é–‹)...")
            smart_scroll_and_expand(page)
            
            pdf_bytes = page.pdf(format="A4", print_background=True)
            return pdf_bytes
        except Exception as e:
            st.error(f"éŒ¯èª¤ï¼š{e}")
            return None
        finally:
            browser.close()

# --- æ¨¡å¼äºŒï¼šæ‰¹æ¬¡ç¶²å€ ---
def generate_batch_pdfs(url_list):
    zip_buffer = io.BytesIO()
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        context = browser.new_context(
             viewport={"width": 1280, "height": 1080},
             user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            total = len(url_list)
            success_count = 0
            
            for i, url in enumerate(url_list):
                status_text.text(f"è™•ç†ä¸­ ({i+1}/{total}): {url}")
                page = context.new_page()
                
                try:
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                    page.emulate_media(media="screen")
                    smart_scroll_and_expand(page)
                    
                    pdf_bytes = page.pdf(format="A4", print_background=True)
                    
                    filename = get_safe_filename(url, i)
                    zip_file.writestr(filename, pdf_bytes)
                    success_count += 1
                    
                except Exception as e:
                    st.error(f"è·³ééŒ¯èª¤é€£çµ {url}: {str(e)[:100]}")
                finally:
                    page.close()
                    
                progress_bar.progress((i + 1) / total)

        browser.close()
        status_text.text(f"ä»»å‹™å®Œæˆï¼æˆåŠŸï¼š{success_count}/{total}")
        
    zip_buffer.seek(0)
    return zip_buffer

# --- UI ä»‹é¢ ---
tab1, tab2 = st.tabs(["ğŸ” å–®ä¸€ç²¾ç¢ºæ“·å–", "ğŸ“š æ‰¹é‡æˆ°ç•¥æ­¸æª”"])

with tab1:
    st.header("å–®ä¸€ç¶²é è½‰ PDF")
    single_url = st.text_input("è¼¸å…¥ç¶²å€", placeholder="https://www.facebook.com/ads/library/...")
    if st.button("åŸ·è¡Œè½‰æ›", key="btn_single"):
        if single_url:
            pdf_data = generate_single_pdf(single_url)
            if pdf_data:
                st.success("è½‰æ›æˆåŠŸï¼")
                st.download_button("ä¸‹è¼‰ PDF", pdf_data, "output.pdf", "application/pdf")

with tab2:
    st.header("æ‰¹é‡ç¶²é è½‰ PDF")
    batch_urls = st.text_area("è¼¸å…¥ç¶²å€åˆ—è¡¨ (è‡ªå‹•éæ¿¾é›œè¨Š)", height=200)
    if st.button("åŸ·è¡Œæ‰¹æ¬¡è½‰æ›", key="btn_batch"):
        # ä½¿ç”¨ Regex éæ¿¾å‡ºç¶²å€ï¼Œæ’é™¤å‰å¾Œç©ºç™½èˆ‡é›œè¨Š
        url_pattern = re.compile(r'(https?://\S+)')
        url_list = list(dict.fromkeys(url_pattern.findall(batch_urls)))
        
        if url_list:
            st.info(f"é–‹å§‹è™•ç† {len(url_list)} å€‹ç¶²å€...")
            zip_result = generate_batch_pdfs(url_list)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            st.download_button("ğŸ“¦ ä¸‹è¼‰ ZIP", zip_result, f"batch_{timestamp}.zip", "application/zip")
        else:
            st.warning("æœªåµæ¸¬åˆ°æœ‰æ•ˆç¶²å€")
