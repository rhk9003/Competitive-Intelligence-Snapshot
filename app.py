import streamlit as st
from playwright.sync_api import sync_playwright
import time
import subprocess
import zipfile
import io
import re
from datetime import datetime

# --- åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro)", layout="centered")
st.title("ğŸ›¡ï¸ ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹")
st.markdown("æˆ°ç•¥è¨˜éŒ„å°ˆç”¨å·¥å…·ï¼šæ”¯æ´ã€Œå–®é»å¿«ç…§ã€èˆ‡ã€Œæ‰¹é‡æ­¸æª”ã€ï¼Œå·²å„ªåŒ–æŠ—å¹²æ“¾èƒ½åŠ›ã€‚")

# --- æ ¸å¿ƒï¼šç’°å¢ƒæª¢æŸ¥ (åªè·‘ä¸€æ¬¡) ---
def ensure_browsers_installed():
    try:
        with sync_playwright() as p:
            p.chromium.launch(headless=True)
    except Exception:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“ (é¦–æ¬¡åŸ·è¡Œéœ€ 30-60 ç§’)..."):
            subprocess.run(["playwright", "install", "chromium"])
            subprocess.run(["playwright", "install-deps"])
            st.success("æ ¸å¿ƒå°±ç·’ï¼")

if 'browser_checked' not in st.session_state:
    ensure_browsers_installed()
    st.session_state['browser_checked'] = True

# --- é€šç”¨å·¥å…·å‡½å¼ ---
def get_safe_filename(url, index=None):
    # ç§»é™¤ http/https
    clean_url = re.sub(r'^https?://', '', url)
    # æ›¿æ›ä¸åˆæ³•å­—å…ƒç‚ºåº•ç·š
    safe_name = re.sub(r'[^a-zA-Z0-9]', '_', clean_url)
    # å¦‚æœæœ‰å‚³å…¥ indexï¼Œä»£è¡¨æ˜¯æ‰¹æ¬¡æ¨¡å¼ï¼ŒåŠ ä¸Šåºè™Ÿ
    if index is not None:
        return f"{index+1:02d}_{safe_name[:50]}.pdf"
    return f"{safe_name[:50]}.pdf"

def scroll_page(page):
    """æ¨¡æ“¬çœŸäººæ»¾å‹•ï¼Œè§¸ç™¼ Lazy Loading"""
    page.evaluate("""
        async () => {
            await new Promise((resolve) => {
                var totalHeight = 0;
                var distance = 100;
                var timer = setInterval(() => {
                    var scrollHeight = document.body.scrollHeight;
                    window.scrollBy(0, distance);
                    totalHeight += distance;
                    if(totalHeight >= scrollHeight - window.innerHeight){
                        clearInterval(timer);
                        resolve();
                    }
                }, 100);
            });
        }
    """)
    time.sleep(2)
    page.evaluate("window.scrollTo(0, 0)")

# --- æ¨¡å¼ä¸€ï¼šå–®ä¸€ç¶²å€è™•ç†é‚è¼¯ ---
def generate_single_pdf(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        page = context.new_page()
        try:
            st.info(f"æ­£åœ¨é€£æ¥ç›®æ¨™ï¼š{url}")
            
            # [é—œéµä¿®æ­£] æ”¹ç”¨ domcontentloaded ä»¥é¿å…è¢«å»£å‘Šè¿½è¹¤ç¢¼å¡æ­» Timeout
            page.goto(url, wait_until="domcontentloaded", timeout=60000)
            page.emulate_media(media="screen")
            
            st.info("æ­£åœ¨åŸ·è¡Œæ·±åº¦æ»¾å‹•æƒæ...")
            scroll_page(page)
            
            pdf_bytes = page.pdf(
                format="A4",
                print_background=True,
                margin={"top": "1cm", "bottom": "1cm", "left": "1cm", "right": "1cm"}
            )
            return pdf_bytes
        except Exception as e:
            st.error(f"æ“·å–å¤±æ•—ï¼š{e}")
            return None
        finally:
            browser.close()

# --- æ¨¡å¼äºŒï¼šæ‰¹æ¬¡ç¶²å€è™•ç†é‚è¼¯ ---
def generate_batch_pdfs(url_list):
    zip_buffer = io.BytesIO()
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        context = browser.new_context(
             user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            total = len(url_list)
            success_count = 0
            
            for i, url in enumerate(url_list):
                status_text.text(f"æ­£åœ¨è™•ç† ({i+1}/{total}): {url}")
                page = context.new_page()
                
                try:
                    # [é—œéµä¿®æ­£] æ”¹ç”¨ domcontentloaded æå‡å° Pixnet ç­‰é‡å»£å‘Šç¶²ç«™çš„ç›¸å®¹æ€§
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                    page.emulate_media(media="screen")
                    scroll_page(page)
                    
                    pdf_bytes = page.pdf(
                        format="A4",
                        print_background=True,
                        margin={"top": "1cm", "bottom": "1cm", "left": "1cm", "right": "1cm"}
                    )
                    
                    filename = get_safe_filename(url, i)
                    zip_file.writestr(filename, pdf_bytes)
                    success_count += 1
                    
                except Exception as e:
                    # å®¹éŒ¯è™•ç†ï¼šå–®ä¸€å¤±æ•—ä¸å½±éŸ¿æ•´é«”ï¼Œåªå°å‡ºéŒ¯èª¤è¨Šæ¯
                    st.error(f"è·³ééŒ¯èª¤é€£çµ {url}: {str(e)[:100]}...") 
                finally:
                    page.close()
                    
                progress_bar.progress((i + 1) / total)

        browser.close()
        status_text.text(f"ä»»å‹™å®Œæˆã€‚æˆåŠŸæ“·å– {success_count} / {total} å€‹é é¢ã€‚")
        
    zip_buffer.seek(0)
    return zip_buffer

# --- UI ä»‹é¢ä½ˆå±€ (Tabs) ---
tab1, tab2 = st.tabs(["ğŸ” å–®ä¸€ç²¾ç¢ºæ“·å–", "ğŸ“š æ‰¹é‡æˆ°ç•¥æ­¸æª”"])

# === Tab 1: å–®ä¸€æ¨¡å¼ ===
with tab1:
    st.header("å–®ä¸€ç¶²é è½‰ PDF")
    single_url = st.text_input("è¼¸å…¥ç¶²å€", placeholder="https://www.example.com")
    
    if st.button("åŸ·è¡Œè½‰æ›", key="btn_single"):
        if not single_url:
            st.warning("è«‹è¼¸å…¥ç¶²å€")
        else:
            pdf_data = generate_single_pdf(single_url)
            if pdf_data:
                file_name = get_safe_filename(single_url)
                st.success("è½‰æ›æˆåŠŸï¼")
                st.download_button(
                    label="ä¸‹è¼‰ PDF",
                    data=pdf_data,
                    file_name=file_name,
                    mime="application/pdf"
                )

# === Tab 2: æ‰¹æ¬¡æ¨¡å¼ (å« Regex å®¹éŒ¯) ===
with tab2:
    st.header("æ‰¹é‡ç¶²é è½‰ PDF (ZIP æ‰“åŒ…)")
    batch_urls = st.text_area(
        "è¼¸å…¥ç¶²å€åˆ—è¡¨ (æ”¯æ´æ··åˆæ–‡å­—è²¼ä¸Šï¼Œç³»çµ±æœƒè‡ªå‹•éæ¿¾å‡ºç¶²å€)", 
        height=200,
        placeholder="å³ä½¿è²¼å…¥å«æœ‰èªªæ˜çš„æ–‡å­—ï¼Œä¾‹å¦‚ï¼š\n1. Googleé¦–é  https://google.com\n2. é›…è™ https://yahoo.com\nç³»çµ±ä¹Ÿèƒ½è‡ªå‹•è­˜åˆ¥ã€‚"
    )
    
    if st.button("åŸ·è¡Œæ‰¹æ¬¡è½‰æ›", key="btn_batch"):
        # --- å‡ç´šå¾Œçš„é‚è¼¯ï¼šä½¿ç”¨ Regex è‡ªå‹•æŠ“å–ç¶²å€ ---
        # å°‹æ‰¾æ‰€æœ‰ä»¥ http æˆ– https é–‹é ­ï¼Œç›´åˆ°é‡åˆ°ç©ºç™½ç‚ºæ­¢çš„å­—ä¸²
        url_pattern = re.compile(r'(https?://\S+)')
        url_list = url_pattern.findall(batch_urls)
        
        # å»é™¤é‡è¤‡ç¶²å€ (ä¿æŒé †åº)
        url_list = list(dict.fromkeys(url_list))

        if not url_list:
            st.warning("âš ï¸ æœªåµæ¸¬åˆ°æœ‰æ•ˆç¶²å€ï¼Œè«‹ç¢ºèªå…§å®¹åŒ…å« http:// æˆ– https://")
        else:
            st.info(f"å·²è­˜åˆ¥ {len(url_list)} å€‹æœ‰æ•ˆç¶²å€ï¼Œé–‹å§‹ä½œæ¥­...")
            
            if len(url_list) > 10:
                st.warning("ğŸ’¡ ç¶²å€è¼ƒå¤šï¼Œè«‹è€å¿ƒç­‰å€™...")
            
            zip_result = generate_batch_pdfs(url_list)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            st.download_button(
                label="ğŸ“¦ ä¸‹è¼‰ ZIP å£“ç¸®æª”",
                data=zip_result,
                file_name=f"strategic_snapshot_{timestamp}.zip",
                mime="application/zip"
            )
