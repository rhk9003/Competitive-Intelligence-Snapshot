import streamlit as st
from playwright.sync_api import sync_playwright
import time
import subprocess
import zipfile
import io
import re
from datetime import datetime

# --- åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro+)", layout="centered")
st.title("ğŸ›¡ï¸ ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro+)")
st.markdown("æˆ°ç•¥è¨˜éŒ„å°ˆç”¨å·¥å…·ï¼šé‡å° Facebook å»£å‘Šæª”æ¡ˆåº«ç­‰ã€Œç„¡é™æ²å‹•ã€ç¶²ç«™é€²è¡Œæ·±åº¦å„ªåŒ–ã€‚")

# --- æ ¸å¿ƒï¼šç’°å¢ƒæª¢æŸ¥ ---
def ensure_browsers_installed():
    try:
        with sync_playwright() as p:
            p.chromium.launch(headless=True)
    except Exception:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“..."):
            subprocess.run(["playwright", "install", "chromium"])
            subprocess.run(["playwright", "install-deps"])
            st.success("æ ¸å¿ƒå°±ç·’ï¼")

if 'browser_checked' not in st.session_state:
    ensure_browsers_installed()
    st.session_state['browser_checked'] = True

# --- é€šç”¨å·¥å…·å‡½å¼ ---
def get_safe_filename(url, index=None):
    clean_url = re.sub(r'^https?://', '', url)
    safe_name = re.sub(r'[^a-zA-Z0-9]', '_', clean_url)
    if index is not None:
        return f"{index+1:02d}_{safe_name[:50]}.pdf"
    return f"{safe_name[:50]}.pdf"

# --- [é—œéµå‡ç´š] æ·±åº¦äº’å‹•æ»¾å‹•é‚è¼¯ ---
def smart_scroll_and_expand(page):
    """
    é‡å° Infinite Scroll ç¶²ç«™çš„æ™ºæ…§æ»¾å‹•èˆ‡é»æ“Šå±•é–‹
    """
    # 1. å˜—è©¦é»æ“Šã€ŒæŸ¥çœ‹æ›´å¤šã€é¡å‹çš„æŒ‰éˆ• (é‡å° FB/IG/æ–°èç¶²ç«™)
    # é€™è£¡ä½¿ç”¨ä¸€äº›å¸¸è¦‹çš„ class æˆ–æ–‡å­—ç‰¹å¾µä¾†å˜—è©¦é»æ“Š
    try:
        page.evaluate("""
            () => {
                // å®šç¾©å¸¸è¦‹çš„å±•é–‹æŒ‰éˆ•é—œéµå­—
                const keywords = ['æŸ¥çœ‹æ›´å¤š', 'é¡¯ç¤ºæ›´å¤š', 'See more', 'Read more', 'å±•é–‹', 'æ›´å¤š'];
                
                // æ‰¾å‡ºæ‰€æœ‰å¯èƒ½æ˜¯æŒ‰éˆ•çš„å…ƒç´ 
                const elements = document.querySelectorAll('div[role="button"], span, a, button');
                
                elements.forEach(el => {
                    if (keywords.some(keyword => el.innerText.includes(keyword))) {
                        try { el.click(); } catch(e) {}
                    }
                });
            }
        """)
    except:
        pass # é»æ“Šå¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹

    # 2. æ™ºæ…§ç„¡é™æ²å‹•
    # ä¸ä½¿ç”¨å›ºå®šçš„ setIntervalï¼Œæ”¹ç”¨ Python æ§åˆ¶çš„è¿´åœˆæª¢æŸ¥é«˜åº¦è®ŠåŒ–
    previous_height = page.evaluate("document.body.scrollHeight")
    
    # æœ€å¤šå˜—è©¦æ»¾å‹• 20 æ¬¡ (é¿å…ç„¡é™å¡æ­»)ï¼Œæ¯æ¬¡é–“éš” 2 ç§’
    for i in range(20):
        # æ»¾å‹•åˆ°åº•éƒ¨
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        
        # ç­‰å¾…å…§å®¹è¼‰å…¥ (Facebook éœ€è¦æ¯”è¼ƒä¹…)
        time.sleep(2.5)
        
        # å†æ¬¡å˜—è©¦é»æ“Šæ–°è¼‰å…¥å…§å®¹çš„ã€ŒæŸ¥çœ‹æ›´å¤šã€
        try:
            page.evaluate("""
                () => {
                    const keywords = ['æŸ¥çœ‹æ›´å¤š', 'See more'];
                    const elements = document.querySelectorAll('div[role="button"], span');
                    elements.forEach(el => {
                        if (keywords.some(keyword => el.innerText.includes(keyword))) {
                            try { el.click(); } catch(e) {}
                        }
                    });
                }
            """)
        except:
            pass

        # æª¢æŸ¥é«˜åº¦æ˜¯å¦è®ŠåŒ–
        new_height = page.evaluate("document.body.scrollHeight")
        if new_height == previous_height:
            # å¦‚æœé«˜åº¦æ²’è®Šï¼Œä»£è¡¨åˆ°åº•äº†ï¼Œè·³å‡ºè¿´åœˆ
            break
        previous_height = new_height

    # æ»¾å›é ‚éƒ¨ä»¥å… PDF åªæœ‰ä¸‹é¢
    page.evaluate("window.scrollTo(0, 0)")
    time.sleep(1) # ç­‰å¾…æ»¾å›é ‚éƒ¨å¾Œçš„æ¸²æŸ“

# --- æ¨¡å¼ä¸€ï¼šå–®ä¸€ç¶²å€ ---
def generate_single_pdf(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        # åŠ å¤§ Viewport è®“æˆªåœ–æ›´å®Œæ•´
        context = browser.new_context(
            viewport={"width": 1280, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        page = context.new_page()
        try:
            st.info(f"æ­£åœ¨é€£æ¥ï¼š{url}")
            page.goto(url, wait_until="domcontentloaded", timeout=60000)
            page.emulate_media(media="screen")
            
            st.info("æ­£åœ¨åŸ·è¡Œæ·±åº¦æŒ–æ˜ (æ»¾å‹•åŠ è¼‰ + è‡ªå‹•å±•é–‹)...")
            smart_scroll_and_expand(page)
            
            pdf_bytes = page.pdf(format="A4", print_background=True)
            return pdf_bytes
        except Exception as e:
            st.error(f"éŒ¯èª¤ï¼š{e}")
            return None
        finally:
            browser.close()

# --- æ¨¡å¼äºŒï¼šæ‰¹æ¬¡ç¶²å€ ---
def generate_batch_pdfs(url_list):
    zip_buffer = io.BytesIO()
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
        context = browser.new_context(
             viewport={"width": 1280, "height": 1080},
             user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            total = len(url_list)
            
            for i, url in enumerate(url_list):
                status_text.text(f"è™•ç†ä¸­ ({i+1}/{total}): {url}")
                page = context.new_page()
                
                try:
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                    page.emulate_media(media="screen")
                    
                    # ä½¿ç”¨æ–°çš„æ™ºæ…§æ»¾å‹•é‚è¼¯
                    smart_scroll_and_expand(page)
                    
                    pdf_bytes = page.pdf(format="A4", print_background=True)
                    
                    filename = get_safe_filename(url, i)
                    zip_file.writestr(filename, pdf_bytes)
                    
                except Exception as e:
                    st.error(f"è·³ééŒ¯èª¤é€£çµ {url}: {str(e)[:100]}")
                finally:
                    page.close()
                    
                progress_bar.progress((i + 1) / total)

        browser.close()
        status_text.text(f"ä»»å‹™å®Œæˆï¼")
        
    zip_buffer.seek(0)
    return zip_buffer

# --- UI ä»‹é¢ ---
tab1, tab2 = st.tabs(["ğŸ” å–®ä¸€ç²¾ç¢ºæ“·å–", "ğŸ“š æ‰¹é‡æˆ°ç•¥æ­¸æª”"])

with tab1:
    st.header("å–®ä¸€ç¶²é è½‰ PDF")
    single_url = st.text_input("è¼¸å…¥ç¶²å€", placeholder="https://www.facebook.com/ads/library/...")
    if st.button("åŸ·è¡Œè½‰æ›", key="btn_single"):
        if single_url:
            pdf_data = generate_single_pdf(single_url)
            if pdf_data:
                st.success("è½‰æ›æˆåŠŸï¼")
                st.download_button("ä¸‹è¼‰ PDF", pdf_data, "output.pdf", "application/pdf")

with tab2:
    st.header("æ‰¹é‡ç¶²é è½‰ PDF")
    batch_urls = st.text_area("è¼¸å…¥ç¶²å€åˆ—è¡¨", height=200)
    if st.button("åŸ·è¡Œæ‰¹æ¬¡è½‰æ›", key="btn_batch"):
        url_pattern = re.compile(r'(https?://\S+)')
        url_list = list(dict.fromkeys(url_pattern.findall(batch_urls)))
        
        if url_list:
            st.info(f"é–‹å§‹è™•ç† {len(url_list)} å€‹ç¶²å€...")
            zip_result = generate_batch_pdfs(url_list)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            st.download_button("ğŸ“¦ ä¸‹è¼‰ ZIP", zip_result, f"batch_{timestamp}.zip", "application/zip")
        else:
            st.warning("æœªåµæ¸¬åˆ°æœ‰æ•ˆç¶²å€")
