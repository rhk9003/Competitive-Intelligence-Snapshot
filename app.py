import streamlit as st
from playwright.sync_api import sync_playwright
import time
import subprocess
import zipfile
import io
import re
from datetime import datetime

# --- åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro+)", layout="centered")
st.title("ğŸ›¡ï¸ ç¶²é æƒ…è³‡æ“·å–åŠ©æ‰‹ (Pro+)")
st.markdown("æˆ°ç•¥è¨˜éŒ„å°ˆç”¨å·¥å…·ï¼šé‡å° Facebook å»£å‘Šæª”æ¡ˆåº«ç­‰ã€Œç„¡é™æ²å‹•ã€ç¶²ç«™é€²è¡Œæ·±åº¦å„ªåŒ–ã€‚")

# --- æ ¸å¿ƒï¼šç’°å¢ƒæª¢æŸ¥ ---
def ensure_browsers_installed():
    try:
        with sync_playwright() as p:
            p.chromium.launch(headless=True)
    except Exception:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“ (ä¸‹è¼‰ç€è¦½å™¨ binary)..."):
            subprocess.run(["playwright", "install", "chromium"])
            st.success("æ ¸å¿ƒå°±ç·’ï¼")

if 'browser_checked' not in st.session_state:
    ensure_browsers_installed()
    st.session_state['browser_checked'] = True

# --- é€šç”¨å·¥å…·å‡½å¼ ---
def get_safe_filename(url, index=None):
    clean_url = re.sub(r'^https?://', '', url)
    safe_name = re.sub(r'[^a-zA-Z0-9]', '_', clean_url)
    if index is not None:
        return f"{index+1:02d}_{safe_name[:50]}.pdf"
    return f"{safe_name[:50]}.pdf"

# --- å°å·¥å…·ï¼šç”¨æ–‡å­—é»æ“Šä¸€æ‰¹æŒ‰éˆ• ---
def click_by_text(page, texts):
    for t in texts:
        try:
            loc = page.locator(f"text={t}")
            count = loc.count()
            for i in range(count):
                try:
                    loc.nth(i).click()
                except:
                    pass
        except:
            # é€™å€‹æ–‡å­—ä¸å­˜åœ¨å°±ç•¥é
            pass

# --- æ·±åº¦äº’å‹•æ»¾å‹•é‚è¼¯ï¼ˆç°¡åŒ–ç©©å®šç‰ˆï¼‰ ---
def smart_scroll_and_expand(page, max_scroll=8):
    """
    é‡å° Infinite Scroll ç¶²ç«™çš„æ™ºæ…§æ»¾å‹•èˆ‡é»æ“Šå±•é–‹ã€‚
    å°ˆé–€è™•ç† FB Ad Library è£¡çš„ï¼š
    - å»£å‘Šè¦é»
    - æŸ¥çœ‹æ‘˜è¦è©³æƒ…
    - æŸ¥çœ‹å»£å‘Šè©³æƒ…
    ä»¥åŠä¸€èˆ¬çš„ã€ŒæŸ¥çœ‹æ›´å¤š / See moreã€ã€‚
    """

    # å…ˆåœ¨ç›®å‰ç•«é¢æŠŠèƒ½å±•é–‹çš„éƒ½å±•é–‹ä¸€æ¬¡
    click_by_text(page, [
        "å»£å‘Šè¦é»", "æŸ¥çœ‹æ‘˜è¦è©³æƒ…", "æŸ¥çœ‹å»£å‘Šè©³æƒ…",
        "æŸ¥çœ‹æ›´å¤š", "é¡¯ç¤ºæ›´å¤š", "See more", "Read more", "å±•é–‹", "æ›´å¤š"
    ])
    time.sleep(1)

    previous_height = page.evaluate("document.body.scrollHeight")

    for i in range(max_scroll):
        # æ²åˆ°æœ€åº•
        page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        time.sleep(2.0)

        # æ²å®Œå†æŠŠæ–°å‡ºç¾çš„æŒ‰éˆ•å±•é–‹ä¸€æ¬¡
        click_by_text(page, [
            "å»£å‘Šè¦é»", "æŸ¥çœ‹æ‘˜è¦è©³æƒ…", "æŸ¥çœ‹å»£å‘Šè©³æƒ…",
            "æŸ¥çœ‹æ›´å¤š", "é¡¯ç¤ºæ›´å¤š", "See more", "Read more", "å±•é–‹", "æ›´å¤š"
        ])

        new_height = page.evaluate("document.body.scrollHeight")
        if new_height == previous_height:
            break
        previous_height = new_height

    # å›åˆ°é ‚ç«¯ï¼Œè®“ PDF å¾æœ€ä¸Šé¢é–‹å§‹
    page.evaluate("window.scrollTo(0, 0)")
    time.sleep(1)

# --- æ¨¡å¼ä¸€ï¼šå–®ä¸€ç¶²å€ ---
def generate_single_pdf(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-dev-shm-usage"]
        )
        context = browser.new_context(
            viewport={"width": 1280, "height": 1080},
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/91.0.4472.124 Safari/537.36"
            )
        )
        page = context.new_page()
        try:
            st.info(f"æ­£åœ¨é€£æ¥ï¼š{url}")
            page.goto(url, wait_until="domcontentloaded", timeout=60000)
            page.emulate_media(media="screen")

            st.info("æ­£åœ¨åŸ·è¡Œæ·±åº¦æŒ–æ˜ (æ»¾å‹•åŠ è¼‰ + è‡ªå‹•å±•é–‹å»£å‘Šè¦é»)...")
            smart_scroll_and_expand(page)

            pdf_bytes = page.pdf(format="A4", print_background=True)
            return pdf_bytes
        except Exception as e:
            st.error(f"éŒ¯èª¤ï¼š{e}")
            return None
        finally:
            browser.close()

# --- æ¨¡å¼äºŒï¼šæ‰¹æ¬¡ç¶²å€ ---
def generate_batch_pdfs(url_list):
    zip_buffer = io.BytesIO()
    progress_bar = st.progress(0)
    status_text = st.empty()

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-dev-shm-usage"]
        )
        context = browser.new_context(
            viewport={"width": 1280, "height": 1080},
            user_agent=(
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/91.0.4472.124 Safari/537.36"
            )
        )

        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
            total = len(url_list)
            success_count = 0

            for i, url in enumerate(url_list):
                status_text.text(f"è™•ç†ä¸­ ({i+1}/{total}): {url}")
                page = context.new_page()

                try:
                    page.goto(url, wait_until="domcontentloaded", timeout=60000)
                    page.emulate_media(media="screen")

                    smart_scroll_and_expand(page)

                    pdf_bytes = page.pdf(format="A4", print_background=True)
                    filename = get_safe_filename(url, i)
                    zip_file.writestr(filename, pdf_bytes)
                    success_count += 1

                except Exception as e:
                    st.error(f"è·³ééŒ¯èª¤é€£çµ {url}: {str(e)[:100]}")
                finally:
                    page.close()

                progress_bar.progress((i + 1) / total)

        browser.close()
        status_text.text(f"ä»»å‹™å®Œæˆï¼æˆåŠŸï¼š{success_count}/{total}")

    zip_buffer.seek(0)
    return zip_buffer

# --- UI ä»‹é¢ ---
tab1, tab2 = st.tabs(["ğŸ” å–®ä¸€ç²¾ç¢ºæ“·å–", "ğŸ“š æ‰¹é‡æˆ°ç•¥æ­¸æª”"])

with tab1:
    st.header("å–®ä¸€ç¶²é è½‰ PDF")
    single_url = st.text_input("è¼¸å…¥ç¶²å€", placeholder="https://www.facebook.com/ads/library/...")
    if st.button("åŸ·è¡Œè½‰æ›", key="btn_single"):
        if single_url:
            pdf_data = generate_single_pdf(single_url)
            if pdf_data:
                st.success("è½‰æ›æˆåŠŸï¼")
                st.download_button("ä¸‹è¼‰ PDF", pdf_data, "output.pdf", "application/pdf")

with tab2:
    st.header("æ‰¹é‡ç¶²é è½‰ PDF")
    batch_urls = st.text_area("è¼¸å…¥ç¶²å€åˆ—è¡¨ (è‡ªå‹•éæ¿¾é›œè¨Š)", height=200)
    if st.button("åŸ·è¡Œæ‰¹æ¬¡è½‰æ›", key="btn_batch"):
        url_pattern = re.compile(r'(https?://\S+)')
        url_list = list(dict.fromkeys(url_pattern.findall(batch_urls)))

        if url_list:
            st.info(f"é–‹å§‹è™•ç† {len(url_list)} å€‹ç¶²å€...")
            zip_result = generate_batch_pdfs(url_list)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            st.download_button(
                "ğŸ“¦ ä¸‹è¼‰ ZIP",
                zip_result,
                f"batch_{timestamp}.zip",
                "application/zip"
            )
        else:
            st.warning("æœªåµæ¸¬åˆ°æœ‰æ•ˆç¶²å€")
